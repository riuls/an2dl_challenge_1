{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "V100",
   "authorship_tag": "ABX9TyPtlaxBjqxaCdbgwOF3c/Jo"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "is2u_GVZ_Be5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1699646680204,
     "user_tz": -60,
     "elapsed": 2115,
     "user": {
      "displayName": "Lorenzo Iori",
      "userId": "16218346580860771751"
     }
    },
    "outputId": "d4da41f9-f4b8-409f-8e2f-9f0a36490ca5"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "%cd /gdrive/My Drive/Homework1"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as tfk\n",
    "from tensorflow.keras import layers as tfkl\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint"
   ],
   "metadata": {
    "id": "WjAZfoaZ_EE9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1699646690932,
     "user_tz": -60,
     "elapsed": 7813,
     "user": {
      "displayName": "Lorenzo Iori",
      "userId": "16218346580860771751"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def load_data(folder=\"public_data.npz\", resolution=96, head_only=False):\n",
    "    images = []\n",
    "\n",
    "    loaded = np.load(folder, allow_pickle=True)\n",
    "\n",
    "    # Iterate through files in the specified folder\n",
    "    for i, img in enumerate(loaded['data']):\n",
    "        # Normalize image pixel values to a float range [0, 1]\n",
    "        img = (img / 255).astype(np.float32)\n",
    "\n",
    "        # Convert image from BGR to RGB\n",
    "        img = img[...,::-1]\n",
    "\n",
    "        # Make the image dataset squared\n",
    "        dim = min(img.shape[:-1])\n",
    "        img = img[(img.shape[0]-dim)//2:(img.shape[0]+dim)//2, (img.shape[1]-dim)//2:(img.shape[1]+dim)//2, :]\n",
    "\n",
    "        # Resize the image to 224x224 pixels\n",
    "        #img = tfkl.Resizing(224, 224)(img)\n",
    "        img = tfkl.Resizing(resolution, resolution)(img)\n",
    "\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "\n",
    "        if (head_only and i == 9):\n",
    "           break\n",
    "\n",
    "    labels = loaded['labels']\n",
    "    loaded.close()\n",
    "\n",
    "    if (head_only):\n",
    "       labels = labels[:10]\n",
    "\n",
    "    y = LabelEncoder().fit_transform(labels)\n",
    "    y = tfk.utils.to_categorical(y, 2)\n",
    "\n",
    "    return np.array(images), y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def display_random_images(X, y, num_img=10):\n",
    "  # Create subplots for displaying items\n",
    "  fig, axes = plt.subplots(2, num_img//2, figsize=(20, 9))\n",
    "  for i in range(num_img):\n",
    "      image = randint(0, X.shape[0] - 1)\n",
    "\n",
    "      ax = axes[i%2, i%num_img//2]\n",
    "      ax.imshow(np.clip(X[image], 0, 255))  # Display clipped item images\n",
    "      ax.text(0.5, -0.1, str(image) + ' ' + str(y[image]), size=12, ha=\"center\", transform=ax.transAxes)\n",
    "      ax.axis('off')\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def delete_outliers(X, y):\n",
    "  shrek = 137\n",
    "  trololo = 5143\n",
    "\n",
    "  new_X = []\n",
    "  new_y = []\n",
    "  outliers_X = []\n",
    "\n",
    "  num_outliers = 0\n",
    "\n",
    "  for i, sample in enumerate(X):\n",
    "    if (not (np.array_equal(sample, X[shrek]) or np.array_equal(sample, X[trololo]))):\n",
    "      new_X.append(sample)\n",
    "      new_y.append(y[i])\n",
    "    else:\n",
    "      outliers_X.append(sample)\n",
    "      num_outliers += 1\n",
    "\n",
    "  return np.array(new_X), np.array(new_y), np.array(outliers_X), num_outliers"
   ],
   "metadata": {
    "id": "ZEUD6tWP_EHq",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1699646692873,
     "user_tz": -60,
     "elapsed": 298,
     "user": {
      "displayName": "Lorenzo Iori",
      "userId": "16218346580860771751"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X, y = load_data('public_data.npz')\n",
    "X, y, out, num_outliers = delete_outliers(X, y)"
   ],
   "metadata": {
    "id": "cmhN8J9y_EKf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1699646713717,
     "user_tz": -60,
     "elapsed": 19074,
     "user": {
      "displayName": "Lorenzo Iori",
      "userId": "16218346580860771751"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Split data into train_val and test sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=800, stratify=np.argmax(y,axis=1))\n",
    "\n",
    "# Further split train_val into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=800, stratify=np.argmax(y_train_val,axis=1))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Vyd9Zib_ENW",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1699646716693,
     "user_tz": -60,
     "elapsed": 758,
     "user": {
      "displayName": "Lorenzo Iori",
      "userId": "16218346580860771751"
     }
    },
    "outputId": "0cb33761-c37e-48ed-d16c-9c5ee63cbb81"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "augment = tf.keras.Sequential([\n",
    "    tfkl.RandomFlip(),\n",
    "    tfkl.RandomTranslation(height_factor = (-0.5,0.5), width_factor = (-0.5,0.5), fill_mode = 'reflect'),\n",
    "    tfkl.RandomZoom(0.2, fill_mode = 'reflect'),\n",
    "    tfkl.RandomBrightness(0.2, value_range=(0,1)),\n",
    "    tfkl.RandomRotation((-1,1), fill_mode = 'reflect'),\n",
    "])\n",
    "\n",
    "new_X_train_1 = augment(X_train[np.where((y_train[:, 0] == 0) & (y_train[:, 1] == 1))])\n",
    "new_X_train_2 = augment(new_X_train_1)\n",
    "augmented_X_train_1 = augment(X_train)\n",
    "augmented_X_train_2 = augment(augmented_X_train_1)\n",
    "\n",
    "\n",
    "X_train = np.append(X_train ,augmented_X_train_1, axis = 0)\n",
    "X_train = np.append(X_train ,augmented_X_train_2, axis = 0)\n",
    "X_train = np.append(X_train ,new_X_train_1, axis = 0)\n",
    "X_train = np.append(X_train ,new_X_train_2, axis = 0)\n",
    "y_train = np.append(y_train, y_train, axis = 0)\n",
    "y_train = np.append(y_train, y_train, axis = 0)\n",
    "for k in range(2*new_X_train_1.shape[0]):\n",
    "    y_train = np.append(y_train, [[0,1]], axis = 0)"
   ],
   "metadata": {
    "id": "2pHEcgTA_EQG",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1699646725551,
     "user_tz": -60,
     "elapsed": 6229,
     "user": {
      "displayName": "Lorenzo Iori",
      "userId": "16218346580860771751"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "input_shape = X.shape[1:]\n",
    "latent_dim = 16"
   ],
   "metadata": {
    "id": "XP_QB9Dc_EY4",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1699646728113,
     "user_tz": -60,
     "elapsed": 451,
     "user": {
      "displayName": "Lorenzo Iori",
      "userId": "16218346580860771751"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "seed = 42\n",
    "import os\n",
    "import random\n",
    "\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)"
   ],
   "metadata": {
    "id": "M-t8fJOkXSbS",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1699646730903,
     "user_tz": -60,
     "elapsed": 429,
     "user": {
      "displayName": "Lorenzo Iori",
      "userId": "16218346580860771751"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_encoder(enc_input_shape=input_shape, enc_output_shape=latent_dim, seed=seed):\n",
    "    tf.random.set_seed(seed)\n",
    "    input_layer = tfkl.Input(shape=enc_input_shape, name='input_layer')\n",
    "    x = tfkl.ZeroPadding2D((2,2))(input_layer)\n",
    "\n",
    "    x = tfkl.Conv2D(64, 5, padding='same', strides = 3)(x)\n",
    "    x = tfkl.BatchNormalization()(x)\n",
    "    x = tfkl.ReLU()(x)\n",
    "    x = tfkl.Dropout(rate = 1/6)(x)\n",
    "\n",
    "    x = tfkl.Conv2D(128, 7, padding='same', strides = 4)(x)\n",
    "    x = tfkl.BatchNormalization()(x)\n",
    "    x = tfkl.ReLU()(x)\n",
    "    x = tfkl.Dropout(rate = 1/6)(x)\n",
    "\n",
    "    x = tfkl.Conv2D(256, 5, padding='same', strides = 3)(x)\n",
    "    x = tfkl.BatchNormalization()(x)\n",
    "    x = tfkl.ReLU()(x)\n",
    "    x = tfkl.Dropout(rate = 1/6)(x)\n",
    "\n",
    "    x = tfkl.Conv2D(512, 3, padding='same', strides = 2)(x)\n",
    "    x = tfkl.BatchNormalization()(x)\n",
    "    x = tfkl.ReLU()(x)\n",
    "    x = tfkl.Dropout(rate = 1/6)(x)\n",
    "\n",
    "    x = tfkl.GlobalAveragePooling2D()(x)\n",
    "    output_layer = tfkl.Dense(enc_output_shape, name='output_layer')(x)\n",
    "\n",
    "    # Connect input and output through the Model class\n",
    "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='encoder')\n",
    "\n",
    "    # Return the discriminator\n",
    "    return model"
   ],
   "metadata": {
    "id": "jLB2ktQ7WKag",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1699646731980,
     "user_tz": -60,
     "elapsed": 2,
     "user": {
      "displayName": "Lorenzo Iori",
      "userId": "16218346580860771751"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "encoder = get_encoder(input_shape)\n",
    "encoder.summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "roOXPFdDWKdV",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1699646733696,
     "user_tz": -60,
     "elapsed": 476,
     "user": {
      "displayName": "Lorenzo Iori",
      "userId": "16218346580860771751"
     }
    },
    "outputId": "b71c7a0a-a0d2-4e04-f6a0-c1a651139e55"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_decoder(dec_input_shape=latent_dim, dec_output_shape=input_shape, seed=seed):\n",
    "    tf.random.set_seed(seed)\n",
    "    input_layer = tfkl.Input(shape=dec_input_shape, name='input_layer')\n",
    "    x = tfkl.Dense(6*6*256)(input_layer)\n",
    "    x = tfkl.BatchNormalization()(x)\n",
    "    x = tfkl.ReLU()(x)\n",
    "    x = tfkl.Dropout(rate = 1/6)(x)\n",
    "    x = tfkl.Reshape((6,6,256))(x)\n",
    "\n",
    "    x = tfkl.Conv2DTranspose(128, 3, padding='same', strides = 2)(x)\n",
    "    x = tfkl.BatchNormalization()(x)\n",
    "    x = tfkl.ReLU()(x)\n",
    "    x = tfkl.Dropout(rate = 1/6)(x)\n",
    "    x = tfkl.Reshape((12,12,128))(x)\n",
    "\n",
    "    x = tfkl.Conv2DTranspose(64, 3, padding='same', strides = 2)(x)\n",
    "    x = tfkl.BatchNormalization()(x)\n",
    "    x = tfkl.ReLU()(x)\n",
    "    x = tfkl.Dropout(rate = 1/6)(x)\n",
    "    x = tfkl.Reshape((24,24,64))(x)\n",
    "\n",
    "    x = tfkl.Conv2DTranspose(32, 5, padding='same', strides = 2)(x)\n",
    "    x = tfkl.BatchNormalization()(x)\n",
    "    x = tfkl.ReLU()(x)\n",
    "    x = tfkl.Dropout(rate = 1/6)(x)\n",
    "    x = tfkl.Reshape((48,48,32))(x)\n",
    "\n",
    "    x = tfkl.Conv2DTranspose(32, 5, padding='same', strides = 2)(x)\n",
    "    x = tfkl.BatchNormalization()(x)\n",
    "    x = tfkl.ReLU()(x)\n",
    "    x = tfkl.Dropout(rate = 1/6)(x)\n",
    "    x = tfkl.Reshape((96,96,32))(x)\n",
    "\n",
    "    x = tfkl.Conv2D(dec_output_shape[-1], 5, padding='same')(x)\n",
    "    x = tfkl.Activation('sigmoid')(x)\n",
    "    output_layer = tfkl.Cropping2D((0,0))(x)\n",
    "\n",
    "    # Connect input and output through the Model class\n",
    "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='decoder')\n",
    "\n",
    "    # Return the discriminator\n",
    "    return model\n",
    "decoder = get_decoder()\n",
    "decoder.summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IUiT0t-rWKgB",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1699646735985,
     "user_tz": -60,
     "elapsed": 790,
     "user": {
      "displayName": "Lorenzo Iori",
      "userId": "16218346580860771751"
     }
    },
    "outputId": "5404c4bf-27aa-4a75-97c9-2bc720d5d0bd"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_autoencoder(ae_input_shape=input_shape, ae_output_shape=input_shape):\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "    encoder = get_encoder()\n",
    "    decoder = get_decoder()\n",
    "\n",
    "    input_layer = tfkl.Input(shape=ae_input_shape)\n",
    "    z = encoder(input_layer)\n",
    "    output_layer = decoder(z)\n",
    "\n",
    "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='autoencoder')\n",
    "    return model\n",
    "autoencoder = get_autoencoder()\n",
    "autoencoder.summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CyUsKxzkWKiq",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1699646738931,
     "user_tz": -60,
     "elapsed": 1747,
     "user": {
      "displayName": "Lorenzo Iori",
      "userId": "16218346580860771751"
     }
    },
    "outputId": "9b7c4eb1-2379-484a-b0a9-b4fe749f8eb7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "learning_rate = 3e-3\n",
    "optimizer = tf.optimizers.AdamW(learning_rate, weight_decay = 5e-4)\n",
    "autoencoder.compile(optimizer=optimizer, loss=tfk.losses.binary_crossentropy, metrics=['mse', 'mae'])\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 300"
   ],
   "metadata": {
    "id": "mCcnvHWCWKlH",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1699646741137,
     "user_tz": -60,
     "elapsed": 539,
     "user": {
      "displayName": "Lorenzo Iori",
      "userId": "16218346580860771751"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "history = autoencoder.fit(\n",
    "    X_train,\n",
    "    X_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(X_val,X_val),\n",
    "    callbacks=[\n",
    "        tfk.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "        tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.9, min_lr=1e-5),\n",
    "    ]\n",
    ").history"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "db3it9FsWKop",
    "outputId": "cbbb63aa-3cf7-4ad2-a448-5ed637304bd8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_reconstructions(model, X, imgs=10, verbose=True):\n",
    "    predictions = model.predict(X, verbose=0)\n",
    "    fig, axs = plt.subplots(2, imgs, figsize=(imgs*2, 4))\n",
    "    for i in range(imgs):\n",
    "        axs[0, i].imshow(np.squeeze(X[i]), cmap=plt.get_cmap('gray'))\n",
    "        axs.flat[i].axis('off')\n",
    "        axs[1, i].imshow(np.squeeze(predictions[i]), cmap=plt.get_cmap('gray'))\n",
    "        axs.flat[i+imgs].axis('off')\n",
    "    axs[0,imgs//2].set_title('Real data')\n",
    "    axs[1,imgs//2].set_title('Reconstructions')\n",
    "    plt.show()"
   ],
   "metadata": {
    "id": "TGJeTlNMXgR1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1699646664876,
     "user_tz": -60,
     "elapsed": 315,
     "user": {
      "displayName": "Lorenzo Iori",
      "userId": "16218346580860771751"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "get_reconstructions(autoencoder, X_train)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "id": "at_Pfz6ldlUL",
    "executionInfo": {
     "status": "error",
     "timestamp": 1699646666036,
     "user_tz": -60,
     "elapsed": 5,
     "user": {
      "displayName": "Lorenzo Iori",
      "userId": "16218346580860771751"
     }
    },
    "outputId": "599ea1b9-8940-4595-c691-f0ade63b7ee3"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
