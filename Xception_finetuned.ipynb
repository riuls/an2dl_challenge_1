{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WHPhlAnlljh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "2e1b58b6-0ec7-42eb-e621-8aa112007f27"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-fc151ea79922>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/gdrive/My Drive/Homework1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/My Drive/Homework1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras as tfk\n",
        "from tensorflow.keras import layers as tfkl\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint"
      ],
      "metadata": {
        "id": "xCvC6R5RlrD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 25\n",
        "import os\n",
        "import random\n",
        "\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)"
      ],
      "metadata": {
        "id": "U27hz-RalrGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(folder=\"public_data.npz\", resolution=96, head_only=False):\n",
        "    images = []\n",
        "\n",
        "    loaded = np.load(folder, allow_pickle=True)\n",
        "\n",
        "    # Iterate through files in the specified folder\n",
        "    for i, img in enumerate(loaded['data']):\n",
        "        # Normalize image pixel values to a float range [0, 1]\n",
        "        #img = (img / 255).astype(np.float32)\n",
        "\n",
        "        # Convert image from BGR to RGB\n",
        "        #img = img[...,::-1]\n",
        "\n",
        "        # Make the image dataset squared\n",
        "        dim = min(img.shape[:-1])\n",
        "        img = img[(img.shape[0]-dim)//2:(img.shape[0]+dim)//2, (img.shape[1]-dim)//2:(img.shape[1]+dim)//2, :]\n",
        "\n",
        "        # Resize the image to 224x224 pixels\n",
        "        #img = tfkl.Resizing(224, 224)(img)\n",
        "        img = tfkl.Resizing(resolution, resolution)(img)\n",
        "\n",
        "        if img is not None:\n",
        "            images.append(img)\n",
        "\n",
        "        if (head_only and i == 9):\n",
        "           break\n",
        "\n",
        "    labels = loaded['labels']\n",
        "    loaded.close()\n",
        "\n",
        "    if (head_only):\n",
        "       labels = labels[:10]\n",
        "\n",
        "    y = LabelEncoder().fit_transform(labels)\n",
        "    y = tfk.utils.to_categorical(y, 2)\n",
        "\n",
        "    return np.array(images), y\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def display_random_images(X, y, num_img=10):\n",
        "  # Create subplots for displaying items\n",
        "  fig, axes = plt.subplots(2, num_img//2, figsize=(20, 9))\n",
        "  for i in range(num_img):\n",
        "      image = randint(0, X.shape[0] - 1)\n",
        "\n",
        "      ax = axes[i%2, i%num_img//2]\n",
        "      ax.imshow(np.clip(X[image], 0, 255))  # Display clipped item images\n",
        "      ax.text(0.5, -0.1, str(image) + ' ' + str(y[image]), size=12, ha=\"center\", transform=ax.transAxes)\n",
        "      ax.axis('off')\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def delete_outliers(X, y):\n",
        "  shrek = 137\n",
        "  trololo = 5143\n",
        "\n",
        "  new_X = []\n",
        "  new_y = []\n",
        "\n",
        "  num_outliers = 0\n",
        "\n",
        "  for i, sample in enumerate(X):\n",
        "    if (not (np.array_equal(sample, X[shrek]) or np.array_equal(sample, X[trololo]))):\n",
        "      new_X.append(sample)\n",
        "      new_y.append(y[i])\n",
        "    else:\n",
        "      num_outliers += 1\n",
        "\n",
        "  return np.array(new_X), np.array(new_y), num_outliers"
      ],
      "metadata": {
        "id": "ajzPa3OIlrIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = load_data('public_data.npz')\n",
        "X, y, num_outliers = delete_outliers(X, y)"
      ],
      "metadata": {
        "id": "5l74ZbmulrLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train_val and test sets\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=500, stratify=np.argmax(y,axis=1))\n",
        "\n",
        "# Further split train_val into train and validation sets\n",
        "X_train, X_val, y_train_0, y_val = train_test_split(X_train_val, y_train_val, test_size=500, stratify=np.argmax(y_train_val,axis=1))\n",
        "\n",
        "print(X_train.shape, y_train_0.shape)\n",
        "print(X_val.shape, y_val.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "dQZ2uDNJlrNW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9ce1988-f5bd-4da3-97c3-4372437d28e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4004, 96, 96, 3) (4004, 2)\n",
            "(500, 96, 96, 3) (500, 2)\n",
            "(500, 96, 96, 3) (500, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "augment1 = tf.keras.Sequential([\n",
        "    tfkl.RandomFlip(),\n",
        "    tfkl.RandomTranslation(height_factor = (-0.2,0.2), width_factor = (-0.2,0.2), fill_mode = 'reflect'),\n",
        "    tfkl.RandomZoom(0.3, fill_mode = 'reflect'),\n",
        "    tfkl.RandomBrightness(0.1, value_range=(0,255)),\n",
        "])\n",
        "\n",
        "augment2 = tf.keras.Sequential([\n",
        "    tfkl.RandomFlip(),\n",
        "    tfkl.RandomZoom(0.4, fill_mode = 'reflect'),\n",
        "    tfkl.RandomBrightness(0.1, value_range=(0,255)),\n",
        "    tfkl.RandomRotation((-1,1), fill_mode = 'reflect'),\n",
        "])\n",
        "\n",
        "new_X_train_1 = augment2(X_train[np.where((y_train_0[:, 0] == 0) & (y_train_0[:, 1] == 1))])\n",
        "augmented_X_train_2 = augment2(X_train)\n",
        "augmented_X_train_1 = augment1(augmented_X_train_2)\n",
        "\n",
        "X_train = np.append(X_train ,augmented_X_train_2, axis = 0)\n",
        "X_train = np.append(X_train ,augmented_X_train_1, axis = 0)\n",
        "X_train = np.append(X_train ,new_X_train_1, axis = 0)\n",
        "\n",
        "y_train = np.append(y_train_0, y_train_0, axis = 0)\n",
        "y_train = np.append(y_train, y_train_0, axis = 0)\n",
        "for k in range(new_X_train_1.shape[0]):\n",
        "    y_train = np.append(y_train, [[0,1]], axis = 0)"
      ],
      "metadata": {
        "id": "Mj4QnhPqlrPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define key model parameters\n",
        "input_shape = X_train.shape[1:]  # Input shape for the model\n",
        "output_shape = y_train.shape[1]  # Output shape for the model\n",
        "batch_size = 16                # Batch size for training, always a power of 2!!\n",
        "epochs = 400"
      ],
      "metadata": {
        "id": "qLWKZnxhlrR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mobile = tfk.applications.Xception(\n",
        "    input_shape=(96, 96, 3),\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    pooling='avg',\n",
        ")\n",
        "mobile.trainable = False"
      ],
      "metadata": {
        "id": "tAbMg5a7lrUY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff2ffbe0-aa4d-4c6a-9c5c-2b6262fd390d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83683744/83683744 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tfk.Input(shape=input_shape)\n",
        "# Connect MobileNetV2 to the input\n",
        "x = mobile(inputs)\n",
        "x = tfkl.Dropout(rate = 1/5)(x)\n",
        "x = tfkl.Dense(64)(x)\n",
        "#x = tfkl.BatchNormalization()(x)\n",
        "x = tfkl.Activation('relu')(x)\n",
        "x = tfkl.Dropout(rate = 1/7)(x)\n",
        "x = tfkl.Dense(16)(x)\n",
        "#x = tfkl.BatchNormalization()(x)\n",
        "x = tfkl.Activation('relu')(x)\n",
        "x = tfkl.Dropout(rate = 1/7)(x)\n",
        "# Add a Dense layer with 2 units and softmax activation as the classifier\n",
        "outputs = tfkl.Dense(2, activation='softmax')(x)\n",
        "\n",
        "# Create a Model connecting input and output\n",
        "model_1 = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n",
        "\n",
        "# Compile the model with Categorical Cross-Entropy loss and Adam optimizer\n",
        "model_1.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.AdamW(learning_rate=1e-3, weight_decay=3e-5), metrics=['accuracy'])\n",
        "\n",
        "# Display model summary\n",
        "model_1.summary()"
      ],
      "metadata": {
        "id": "-oliHEELlrX0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3afd3f6-7d27-4150-bbdf-7ccc9c127025"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 96, 96, 3)]       0         \n",
            "                                                                 \n",
            " xception (Functional)       (None, 2048)              20861480  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                131136    \n",
            "                                                                 \n",
            " activation (Activation)     (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 16)                1040      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 16)                0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 34        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20993690 (80.08 MB)\n",
            "Trainable params: 132210 (516.45 KB)\n",
            "Non-trainable params: 20861480 (79.58 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_1.fit(\n",
        "    x = tfk.applications.xception.preprocess_input(X_train), # We need to apply the preprocessing thought for the MobileNetV2 network\n",
        "    y = y_train,\n",
        "    batch_size = 16,\n",
        "    epochs = 400,\n",
        "    validation_data = (tfk.applications.xception.preprocess_input(X_val), y_val), # We need to apply the preprocessing thought for the MobileNetV2 network\n",
        "    callbacks = [\n",
        "        tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=30, restore_best_weights=True),\n",
        "        tfk.callbacks.ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.9, patience = 8, min_lr = 2e-6)\n",
        "    ]\n",
        ").history"
      ],
      "metadata": {
        "id": "g8PvVuy7mH3U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbe18a5b-d755-4997-9ff2-c37fb80a19b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "846/846 [==============================] - 34s 24ms/step - loss: 0.5963 - accuracy: 0.6818 - val_loss: 0.4892 - val_accuracy: 0.7840 - lr: 0.0010\n",
            "Epoch 2/400\n",
            "846/846 [==============================] - 17s 21ms/step - loss: 0.5448 - accuracy: 0.7252 - val_loss: 0.4780 - val_accuracy: 0.8000 - lr: 0.0010\n",
            "Epoch 3/400\n",
            "846/846 [==============================] - 17s 20ms/step - loss: 0.5259 - accuracy: 0.7338 - val_loss: 0.4477 - val_accuracy: 0.8160 - lr: 0.0010\n",
            "Epoch 4/400\n",
            "846/846 [==============================] - 17s 20ms/step - loss: 0.5053 - accuracy: 0.7502 - val_loss: 0.4617 - val_accuracy: 0.8060 - lr: 0.0010\n",
            "Epoch 5/400\n",
            "846/846 [==============================] - 17s 21ms/step - loss: 0.4885 - accuracy: 0.7577 - val_loss: 0.4721 - val_accuracy: 0.8040 - lr: 0.0010\n",
            "Epoch 6/400\n",
            "846/846 [==============================] - 18s 21ms/step - loss: 0.4714 - accuracy: 0.7685 - val_loss: 0.4529 - val_accuracy: 0.8080 - lr: 0.0010\n",
            "Epoch 7/400\n",
            "846/846 [==============================] - 18s 21ms/step - loss: 0.4576 - accuracy: 0.7833 - val_loss: 0.4452 - val_accuracy: 0.8040 - lr: 0.0010\n",
            "Epoch 8/400\n",
            "846/846 [==============================] - 17s 20ms/step - loss: 0.4447 - accuracy: 0.7872 - val_loss: 0.4274 - val_accuracy: 0.8180 - lr: 0.0010\n",
            "Epoch 9/400\n",
            "846/846 [==============================] - 17s 20ms/step - loss: 0.4235 - accuracy: 0.8008 - val_loss: 0.4507 - val_accuracy: 0.8000 - lr: 0.0010\n",
            "Epoch 10/400\n",
            "846/846 [==============================] - 18s 21ms/step - loss: 0.4169 - accuracy: 0.8022 - val_loss: 0.4309 - val_accuracy: 0.8040 - lr: 0.0010\n",
            "Epoch 11/400\n",
            "846/846 [==============================] - 17s 20ms/step - loss: 0.4076 - accuracy: 0.8098 - val_loss: 0.4295 - val_accuracy: 0.8220 - lr: 0.0010\n",
            "Epoch 12/400\n",
            "846/846 [==============================] - 17s 20ms/step - loss: 0.3882 - accuracy: 0.8185 - val_loss: 0.4517 - val_accuracy: 0.8120 - lr: 0.0010\n",
            "Epoch 13/400\n",
            "846/846 [==============================] - 17s 20ms/step - loss: 0.3777 - accuracy: 0.8307 - val_loss: 0.4408 - val_accuracy: 0.8200 - lr: 0.0010\n",
            "Epoch 14/400\n",
            "846/846 [==============================] - 17s 21ms/step - loss: 0.3669 - accuracy: 0.8331 - val_loss: 0.4882 - val_accuracy: 0.7960 - lr: 0.0010\n",
            "Epoch 15/400\n",
            "846/846 [==============================] - 17s 20ms/step - loss: 0.3609 - accuracy: 0.8344 - val_loss: 0.4690 - val_accuracy: 0.7960 - lr: 0.0010\n",
            "Epoch 16/400\n",
            "846/846 [==============================] - 17s 20ms/step - loss: 0.3460 - accuracy: 0.8410 - val_loss: 0.5017 - val_accuracy: 0.7640 - lr: 0.0010\n",
            "Epoch 17/400\n",
            "846/846 [==============================] - 17s 21ms/step - loss: 0.3455 - accuracy: 0.8415 - val_loss: 0.4690 - val_accuracy: 0.7860 - lr: 0.0010\n",
            "Epoch 18/400\n",
            "846/846 [==============================] - 18s 21ms/step - loss: 0.3392 - accuracy: 0.8441 - val_loss: 0.4726 - val_accuracy: 0.8060 - lr: 0.0010\n",
            "Epoch 19/400\n",
            "846/846 [==============================] - 17s 20ms/step - loss: 0.3230 - accuracy: 0.8527 - val_loss: 0.4614 - val_accuracy: 0.7920 - lr: 0.0010\n",
            "Epoch 20/400\n",
            "846/846 [==============================] - 17s 20ms/step - loss: 0.3108 - accuracy: 0.8610 - val_loss: 0.4864 - val_accuracy: 0.7940 - lr: 9.0000e-04\n",
            "Epoch 21/400\n",
            "846/846 [==============================] - 17s 20ms/step - loss: 0.3094 - accuracy: 0.8604 - val_loss: 0.4968 - val_accuracy: 0.7860 - lr: 9.0000e-04\n",
            "Epoch 22/400\n",
            "846/846 [==============================] - 18s 21ms/step - loss: 0.2928 - accuracy: 0.8695 - val_loss: 0.5163 - val_accuracy: 0.7960 - lr: 9.0000e-04\n",
            "Epoch 23/400\n",
            "846/846 [==============================] - 17s 20ms/step - loss: 0.2948 - accuracy: 0.8679 - val_loss: 0.4957 - val_accuracy: 0.7840 - lr: 9.0000e-04\n",
            "Epoch 24/400\n",
            "846/846 [==============================] - 17s 20ms/step - loss: 0.2896 - accuracy: 0.8722 - val_loss: 0.4703 - val_accuracy: 0.8140 - lr: 9.0000e-04\n",
            "Epoch 25/400\n",
            "846/846 [==============================] - 17s 20ms/step - loss: 0.2844 - accuracy: 0.8735 - val_loss: 0.4925 - val_accuracy: 0.7900 - lr: 9.0000e-04\n",
            "Epoch 26/400\n",
            "846/846 [==============================] - 17s 20ms/step - loss: 0.2795 - accuracy: 0.8747 - val_loss: 0.5176 - val_accuracy: 0.8060 - lr: 9.0000e-04\n",
            "Epoch 27/400\n",
            "846/846 [==============================] - 17s 20ms/step - loss: 0.2741 - accuracy: 0.8771 - val_loss: 0.5218 - val_accuracy: 0.8020 - lr: 9.0000e-04\n",
            "Epoch 28/400\n",
            "846/846 [==============================] - 17s 20ms/step - loss: 0.2670 - accuracy: 0.8834 - val_loss: 0.5007 - val_accuracy: 0.8060 - lr: 8.1000e-04\n",
            "Epoch 29/400\n",
            "846/846 [==============================] - 17s 20ms/step - loss: 0.2673 - accuracy: 0.8823 - val_loss: 0.5121 - val_accuracy: 0.8020 - lr: 8.1000e-04\n",
            "Epoch 30/400\n",
            "846/846 [==============================] - 17s 20ms/step - loss: 0.2614 - accuracy: 0.8854 - val_loss: 0.5097 - val_accuracy: 0.7780 - lr: 8.1000e-04\n",
            "Epoch 31/400\n",
            "846/846 [==============================] - 17s 20ms/step - loss: 0.2528 - accuracy: 0.8887 - val_loss: 0.5420 - val_accuracy: 0.7960 - lr: 8.1000e-04\n",
            "Epoch 32/400\n",
            "846/846 [==============================] - 17s 20ms/step - loss: 0.2528 - accuracy: 0.8898 - val_loss: 0.5202 - val_accuracy: 0.8080 - lr: 8.1000e-04\n",
            "Epoch 33/400\n",
            "846/846 [==============================] - 17s 20ms/step - loss: 0.2454 - accuracy: 0.8951 - val_loss: 0.5132 - val_accuracy: 0.7780 - lr: 8.1000e-04\n",
            "Epoch 34/400\n",
            "846/846 [==============================] - 17s 20ms/step - loss: 0.2468 - accuracy: 0.8929 - val_loss: 0.5717 - val_accuracy: 0.7680 - lr: 8.1000e-04\n",
            "Epoch 35/400\n",
            "846/846 [==============================] - 17s 20ms/step - loss: 0.2398 - accuracy: 0.8941 - val_loss: 0.5310 - val_accuracy: 0.8160 - lr: 8.1000e-04\n",
            "Epoch 36/400\n",
            "846/846 [==============================] - 17s 20ms/step - loss: 0.2343 - accuracy: 0.9011 - val_loss: 0.5578 - val_accuracy: 0.7840 - lr: 7.2900e-04\n",
            "Epoch 37/400\n",
            "846/846 [==============================] - 17s 20ms/step - loss: 0.2307 - accuracy: 0.8975 - val_loss: 0.5524 - val_accuracy: 0.7920 - lr: 7.2900e-04\n",
            "Epoch 38/400\n",
            "846/846 [==============================] - 17s 20ms/step - loss: 0.2294 - accuracy: 0.8993 - val_loss: 0.5534 - val_accuracy: 0.8060 - lr: 7.2900e-04\n",
            "Epoch 39/400\n",
            "846/846 [==============================] - 17s 20ms/step - loss: 0.2278 - accuracy: 0.9023 - val_loss: 0.5632 - val_accuracy: 0.7820 - lr: 7.2900e-04\n",
            "Epoch 40/400\n",
            "846/846 [==============================] - 17s 20ms/step - loss: 0.2273 - accuracy: 0.9008 - val_loss: 0.5975 - val_accuracy: 0.7780 - lr: 7.2900e-04\n",
            "Epoch 41/400\n",
            "846/846 [==============================] - 17s 20ms/step - loss: 0.2194 - accuracy: 0.9062 - val_loss: 0.5444 - val_accuracy: 0.8000 - lr: 7.2900e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_accuracy = model_1.evaluate(tfk.applications.xception.preprocess_input(X_test),y_test,verbose=0)[-1]\n",
        "print('Test set accuracy %.4f' % test_accuracy)"
      ],
      "metadata": {
        "id": "S7E-lu3LmH5n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da2cb7c3-989a-44c7-b3f0-59487a0e8393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set accuracy 0.8220\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.save('Xception_NO_INVERSION_nobatchnorm')\n",
        "del model_1"
      ],
      "metadata": {
        "id": "vbvY6j8fmH8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft_model = tfk.models.load_model('Xception_NO_INVERSION')"
      ],
      "metadata": {
        "id": "TsmY6cBdzTno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft_model.get_layer('xception').trainable = True\n",
        "ft_model.get_layer('xception').summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2A_uYFguqVQ",
        "outputId": "65f27a06-d973-4662-a61b-d87268cf8c7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"xception\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 96, 96, 3)]          0         []                            \n",
            "                                                                                                  \n",
            " block1_conv1 (Conv2D)       (None, 47, 47, 32)           864       ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " block1_conv1_bn (BatchNorm  (None, 47, 47, 32)           128       ['block1_conv1[0][0]']        \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block1_conv1_act (Activati  (None, 47, 47, 32)           0         ['block1_conv1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block1_conv2 (Conv2D)       (None, 45, 45, 64)           18432     ['block1_conv1_act[0][0]']    \n",
            "                                                                                                  \n",
            " block1_conv2_bn (BatchNorm  (None, 45, 45, 64)           256       ['block1_conv2[0][0]']        \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block1_conv2_act (Activati  (None, 45, 45, 64)           0         ['block1_conv2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block2_sepconv1 (Separable  (None, 45, 45, 128)          8768      ['block1_conv2_act[0][0]']    \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " block2_sepconv1_bn (BatchN  (None, 45, 45, 128)          512       ['block2_sepconv1[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block2_sepconv2_act (Activ  (None, 45, 45, 128)          0         ['block2_sepconv1_bn[0][0]']  \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " block2_sepconv2 (Separable  (None, 45, 45, 128)          17536     ['block2_sepconv2_act[0][0]'] \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " block2_sepconv2_bn (BatchN  (None, 45, 45, 128)          512       ['block2_sepconv2[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 23, 23, 128)          8192      ['block1_conv2_act[0][0]']    \n",
            "                                                                                                  \n",
            " block2_pool (MaxPooling2D)  (None, 23, 23, 128)          0         ['block2_sepconv2_bn[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 23, 23, 128)          512       ['conv2d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 23, 23, 128)          0         ['block2_pool[0][0]',         \n",
            "                                                                     'batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " block3_sepconv1_act (Activ  (None, 23, 23, 128)          0         ['add[0][0]']                 \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " block3_sepconv1 (Separable  (None, 23, 23, 256)          33920     ['block3_sepconv1_act[0][0]'] \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " block3_sepconv1_bn (BatchN  (None, 23, 23, 256)          1024      ['block3_sepconv1[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block3_sepconv2_act (Activ  (None, 23, 23, 256)          0         ['block3_sepconv1_bn[0][0]']  \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " block3_sepconv2 (Separable  (None, 23, 23, 256)          67840     ['block3_sepconv2_act[0][0]'] \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " block3_sepconv2_bn (BatchN  (None, 23, 23, 256)          1024      ['block3_sepconv2[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 12, 12, 256)          32768     ['add[0][0]']                 \n",
            "                                                                                                  \n",
            " block3_pool (MaxPooling2D)  (None, 12, 12, 256)          0         ['block3_sepconv2_bn[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 12, 12, 256)          1024      ['conv2d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, 12, 12, 256)          0         ['block3_pool[0][0]',         \n",
            "                                                                     'batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " block4_sepconv1_act (Activ  (None, 12, 12, 256)          0         ['add_1[0][0]']               \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " block4_sepconv1 (Separable  (None, 12, 12, 728)          188672    ['block4_sepconv1_act[0][0]'] \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " block4_sepconv1_bn (BatchN  (None, 12, 12, 728)          2912      ['block4_sepconv1[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block4_sepconv2_act (Activ  (None, 12, 12, 728)          0         ['block4_sepconv1_bn[0][0]']  \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " block4_sepconv2 (Separable  (None, 12, 12, 728)          536536    ['block4_sepconv2_act[0][0]'] \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " block4_sepconv2_bn (BatchN  (None, 12, 12, 728)          2912      ['block4_sepconv2[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 6, 6, 728)            186368    ['add_1[0][0]']               \n",
            "                                                                                                  \n",
            " block4_pool (MaxPooling2D)  (None, 6, 6, 728)            0         ['block4_sepconv2_bn[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 6, 6, 728)            2912      ['conv2d_2[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 6, 6, 728)            0         ['block4_pool[0][0]',         \n",
            "                                                                     'batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " block5_sepconv1_act (Activ  (None, 6, 6, 728)            0         ['add_2[0][0]']               \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " block5_sepconv1 (Separable  (None, 6, 6, 728)            536536    ['block5_sepconv1_act[0][0]'] \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " block5_sepconv1_bn (BatchN  (None, 6, 6, 728)            2912      ['block5_sepconv1[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block5_sepconv2_act (Activ  (None, 6, 6, 728)            0         ['block5_sepconv1_bn[0][0]']  \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " block5_sepconv2 (Separable  (None, 6, 6, 728)            536536    ['block5_sepconv2_act[0][0]'] \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " block5_sepconv2_bn (BatchN  (None, 6, 6, 728)            2912      ['block5_sepconv2[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block5_sepconv3_act (Activ  (None, 6, 6, 728)            0         ['block5_sepconv2_bn[0][0]']  \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " block5_sepconv3 (Separable  (None, 6, 6, 728)            536536    ['block5_sepconv3_act[0][0]'] \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " block5_sepconv3_bn (BatchN  (None, 6, 6, 728)            2912      ['block5_sepconv3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_3 (Add)                 (None, 6, 6, 728)            0         ['block5_sepconv3_bn[0][0]',  \n",
            "                                                                     'add_2[0][0]']               \n",
            "                                                                                                  \n",
            " block6_sepconv1_act (Activ  (None, 6, 6, 728)            0         ['add_3[0][0]']               \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " block6_sepconv1 (Separable  (None, 6, 6, 728)            536536    ['block6_sepconv1_act[0][0]'] \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " block6_sepconv1_bn (BatchN  (None, 6, 6, 728)            2912      ['block6_sepconv1[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block6_sepconv2_act (Activ  (None, 6, 6, 728)            0         ['block6_sepconv1_bn[0][0]']  \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " block6_sepconv2 (Separable  (None, 6, 6, 728)            536536    ['block6_sepconv2_act[0][0]'] \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " block6_sepconv2_bn (BatchN  (None, 6, 6, 728)            2912      ['block6_sepconv2[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block6_sepconv3_act (Activ  (None, 6, 6, 728)            0         ['block6_sepconv2_bn[0][0]']  \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " block6_sepconv3 (Separable  (None, 6, 6, 728)            536536    ['block6_sepconv3_act[0][0]'] \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " block6_sepconv3_bn (BatchN  (None, 6, 6, 728)            2912      ['block6_sepconv3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_4 (Add)                 (None, 6, 6, 728)            0         ['block6_sepconv3_bn[0][0]',  \n",
            "                                                                     'add_3[0][0]']               \n",
            "                                                                                                  \n",
            " block7_sepconv1_act (Activ  (None, 6, 6, 728)            0         ['add_4[0][0]']               \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " block7_sepconv1 (Separable  (None, 6, 6, 728)            536536    ['block7_sepconv1_act[0][0]'] \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " block7_sepconv1_bn (BatchN  (None, 6, 6, 728)            2912      ['block7_sepconv1[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block7_sepconv2_act (Activ  (None, 6, 6, 728)            0         ['block7_sepconv1_bn[0][0]']  \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " block7_sepconv2 (Separable  (None, 6, 6, 728)            536536    ['block7_sepconv2_act[0][0]'] \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " block7_sepconv2_bn (BatchN  (None, 6, 6, 728)            2912      ['block7_sepconv2[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block7_sepconv3_act (Activ  (None, 6, 6, 728)            0         ['block7_sepconv2_bn[0][0]']  \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " block7_sepconv3 (Separable  (None, 6, 6, 728)            536536    ['block7_sepconv3_act[0][0]'] \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " block7_sepconv3_bn (BatchN  (None, 6, 6, 728)            2912      ['block7_sepconv3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_5 (Add)                 (None, 6, 6, 728)            0         ['block7_sepconv3_bn[0][0]',  \n",
            "                                                                     'add_4[0][0]']               \n",
            "                                                                                                  \n",
            " block8_sepconv1_act (Activ  (None, 6, 6, 728)            0         ['add_5[0][0]']               \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " block8_sepconv1 (Separable  (None, 6, 6, 728)            536536    ['block8_sepconv1_act[0][0]'] \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " block8_sepconv1_bn (BatchN  (None, 6, 6, 728)            2912      ['block8_sepconv1[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block8_sepconv2_act (Activ  (None, 6, 6, 728)            0         ['block8_sepconv1_bn[0][0]']  \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " block8_sepconv2 (Separable  (None, 6, 6, 728)            536536    ['block8_sepconv2_act[0][0]'] \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " block8_sepconv2_bn (BatchN  (None, 6, 6, 728)            2912      ['block8_sepconv2[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block8_sepconv3_act (Activ  (None, 6, 6, 728)            0         ['block8_sepconv2_bn[0][0]']  \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " block8_sepconv3 (Separable  (None, 6, 6, 728)            536536    ['block8_sepconv3_act[0][0]'] \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " block8_sepconv3_bn (BatchN  (None, 6, 6, 728)            2912      ['block8_sepconv3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_6 (Add)                 (None, 6, 6, 728)            0         ['block8_sepconv3_bn[0][0]',  \n",
            "                                                                     'add_5[0][0]']               \n",
            "                                                                                                  \n",
            " block9_sepconv1_act (Activ  (None, 6, 6, 728)            0         ['add_6[0][0]']               \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " block9_sepconv1 (Separable  (None, 6, 6, 728)            536536    ['block9_sepconv1_act[0][0]'] \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " block9_sepconv1_bn (BatchN  (None, 6, 6, 728)            2912      ['block9_sepconv1[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block9_sepconv2_act (Activ  (None, 6, 6, 728)            0         ['block9_sepconv1_bn[0][0]']  \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " block9_sepconv2 (Separable  (None, 6, 6, 728)            536536    ['block9_sepconv2_act[0][0]'] \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " block9_sepconv2_bn (BatchN  (None, 6, 6, 728)            2912      ['block9_sepconv2[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block9_sepconv3_act (Activ  (None, 6, 6, 728)            0         ['block9_sepconv2_bn[0][0]']  \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " block9_sepconv3 (Separable  (None, 6, 6, 728)            536536    ['block9_sepconv3_act[0][0]'] \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " block9_sepconv3_bn (BatchN  (None, 6, 6, 728)            2912      ['block9_sepconv3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_7 (Add)                 (None, 6, 6, 728)            0         ['block9_sepconv3_bn[0][0]',  \n",
            "                                                                     'add_6[0][0]']               \n",
            "                                                                                                  \n",
            " block10_sepconv1_act (Acti  (None, 6, 6, 728)            0         ['add_7[0][0]']               \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " block10_sepconv1 (Separabl  (None, 6, 6, 728)            536536    ['block10_sepconv1_act[0][0]']\n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " block10_sepconv1_bn (Batch  (None, 6, 6, 728)            2912      ['block10_sepconv1[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block10_sepconv2_act (Acti  (None, 6, 6, 728)            0         ['block10_sepconv1_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " block10_sepconv2 (Separabl  (None, 6, 6, 728)            536536    ['block10_sepconv2_act[0][0]']\n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " block10_sepconv2_bn (Batch  (None, 6, 6, 728)            2912      ['block10_sepconv2[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block10_sepconv3_act (Acti  (None, 6, 6, 728)            0         ['block10_sepconv2_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " block10_sepconv3 (Separabl  (None, 6, 6, 728)            536536    ['block10_sepconv3_act[0][0]']\n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " block10_sepconv3_bn (Batch  (None, 6, 6, 728)            2912      ['block10_sepconv3[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_8 (Add)                 (None, 6, 6, 728)            0         ['block10_sepconv3_bn[0][0]', \n",
            "                                                                     'add_7[0][0]']               \n",
            "                                                                                                  \n",
            " block11_sepconv1_act (Acti  (None, 6, 6, 728)            0         ['add_8[0][0]']               \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " block11_sepconv1 (Separabl  (None, 6, 6, 728)            536536    ['block11_sepconv1_act[0][0]']\n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " block11_sepconv1_bn (Batch  (None, 6, 6, 728)            2912      ['block11_sepconv1[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block11_sepconv2_act (Acti  (None, 6, 6, 728)            0         ['block11_sepconv1_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " block11_sepconv2 (Separabl  (None, 6, 6, 728)            536536    ['block11_sepconv2_act[0][0]']\n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " block11_sepconv2_bn (Batch  (None, 6, 6, 728)            2912      ['block11_sepconv2[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block11_sepconv3_act (Acti  (None, 6, 6, 728)            0         ['block11_sepconv2_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " block11_sepconv3 (Separabl  (None, 6, 6, 728)            536536    ['block11_sepconv3_act[0][0]']\n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " block11_sepconv3_bn (Batch  (None, 6, 6, 728)            2912      ['block11_sepconv3[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_9 (Add)                 (None, 6, 6, 728)            0         ['block11_sepconv3_bn[0][0]', \n",
            "                                                                     'add_8[0][0]']               \n",
            "                                                                                                  \n",
            " block12_sepconv1_act (Acti  (None, 6, 6, 728)            0         ['add_9[0][0]']               \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " block12_sepconv1 (Separabl  (None, 6, 6, 728)            536536    ['block12_sepconv1_act[0][0]']\n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " block12_sepconv1_bn (Batch  (None, 6, 6, 728)            2912      ['block12_sepconv1[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block12_sepconv2_act (Acti  (None, 6, 6, 728)            0         ['block12_sepconv1_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " block12_sepconv2 (Separabl  (None, 6, 6, 728)            536536    ['block12_sepconv2_act[0][0]']\n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " block12_sepconv2_bn (Batch  (None, 6, 6, 728)            2912      ['block12_sepconv2[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block12_sepconv3_act (Acti  (None, 6, 6, 728)            0         ['block12_sepconv2_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " block12_sepconv3 (Separabl  (None, 6, 6, 728)            536536    ['block12_sepconv3_act[0][0]']\n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " block12_sepconv3_bn (Batch  (None, 6, 6, 728)            2912      ['block12_sepconv3[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_10 (Add)                (None, 6, 6, 728)            0         ['block12_sepconv3_bn[0][0]', \n",
            "                                                                     'add_9[0][0]']               \n",
            "                                                                                                  \n",
            " block13_sepconv1_act (Acti  (None, 6, 6, 728)            0         ['add_10[0][0]']              \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " block13_sepconv1 (Separabl  (None, 6, 6, 728)            536536    ['block13_sepconv1_act[0][0]']\n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " block13_sepconv1_bn (Batch  (None, 6, 6, 728)            2912      ['block13_sepconv1[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block13_sepconv2_act (Acti  (None, 6, 6, 728)            0         ['block13_sepconv1_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " block13_sepconv2 (Separabl  (None, 6, 6, 1024)           752024    ['block13_sepconv2_act[0][0]']\n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " block13_sepconv2_bn (Batch  (None, 6, 6, 1024)           4096      ['block13_sepconv2[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 3, 3, 1024)           745472    ['add_10[0][0]']              \n",
            "                                                                                                  \n",
            " block13_pool (MaxPooling2D  (None, 3, 3, 1024)           0         ['block13_sepconv2_bn[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 3, 3, 1024)           4096      ['conv2d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add_11 (Add)                (None, 3, 3, 1024)           0         ['block13_pool[0][0]',        \n",
            "                                                                     'batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " block14_sepconv1 (Separabl  (None, 3, 3, 1536)           1582080   ['add_11[0][0]']              \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " block14_sepconv1_bn (Batch  (None, 3, 3, 1536)           6144      ['block14_sepconv1[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block14_sepconv1_act (Acti  (None, 3, 3, 1536)           0         ['block14_sepconv1_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " block14_sepconv2 (Separabl  (None, 3, 3, 2048)           3159552   ['block14_sepconv1_act[0][0]']\n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " block14_sepconv2_bn (Batch  (None, 3, 3, 2048)           8192      ['block14_sepconv2[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block14_sepconv2_act (Acti  (None, 3, 3, 2048)           0         ['block14_sepconv2_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " global_average_pooling2d (  (None, 2048)                 0         ['block14_sepconv2_act[0][0]']\n",
            " GlobalAveragePooling2D)                                                                          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 20861480 (79.58 MB)\n",
            "Trainable params: 20806952 (79.37 MB)\n",
            "Non-trainable params: 54528 (213.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze up to last N layers\n",
        "N = 7    # last block\n",
        "for i, layer in enumerate(ft_model.get_layer('xception').layers[:-N]):\n",
        "  layer.trainable=False"
      ],
      "metadata": {
        "id": "CliFxQGduqYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, layer in enumerate(ft_model.get_layer('xception').layers):\n",
        "  print(layer.name, layer.trainable)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yPceu-Cuqac",
        "outputId": "658b8b04-adfd-4615-bce4-cdfd3f5c0709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_1 False\n",
            "block1_conv1 False\n",
            "block1_conv1_bn False\n",
            "block1_conv1_act False\n",
            "block1_conv2 False\n",
            "block1_conv2_bn False\n",
            "block1_conv2_act False\n",
            "block2_sepconv1 False\n",
            "block2_sepconv1_bn False\n",
            "block2_sepconv2_act False\n",
            "block2_sepconv2 False\n",
            "block2_sepconv2_bn False\n",
            "conv2d False\n",
            "block2_pool False\n",
            "batch_normalization False\n",
            "add False\n",
            "block3_sepconv1_act False\n",
            "block3_sepconv1 False\n",
            "block3_sepconv1_bn False\n",
            "block3_sepconv2_act False\n",
            "block3_sepconv2 False\n",
            "block3_sepconv2_bn False\n",
            "conv2d_1 False\n",
            "block3_pool False\n",
            "batch_normalization_1 False\n",
            "add_1 False\n",
            "block4_sepconv1_act False\n",
            "block4_sepconv1 False\n",
            "block4_sepconv1_bn False\n",
            "block4_sepconv2_act False\n",
            "block4_sepconv2 False\n",
            "block4_sepconv2_bn False\n",
            "conv2d_2 False\n",
            "block4_pool False\n",
            "batch_normalization_2 False\n",
            "add_2 False\n",
            "block5_sepconv1_act False\n",
            "block5_sepconv1 False\n",
            "block5_sepconv1_bn False\n",
            "block5_sepconv2_act False\n",
            "block5_sepconv2 False\n",
            "block5_sepconv2_bn False\n",
            "block5_sepconv3_act False\n",
            "block5_sepconv3 False\n",
            "block5_sepconv3_bn False\n",
            "add_3 False\n",
            "block6_sepconv1_act False\n",
            "block6_sepconv1 False\n",
            "block6_sepconv1_bn False\n",
            "block6_sepconv2_act False\n",
            "block6_sepconv2 False\n",
            "block6_sepconv2_bn False\n",
            "block6_sepconv3_act False\n",
            "block6_sepconv3 False\n",
            "block6_sepconv3_bn False\n",
            "add_4 False\n",
            "block7_sepconv1_act False\n",
            "block7_sepconv1 False\n",
            "block7_sepconv1_bn False\n",
            "block7_sepconv2_act False\n",
            "block7_sepconv2 False\n",
            "block7_sepconv2_bn False\n",
            "block7_sepconv3_act False\n",
            "block7_sepconv3 False\n",
            "block7_sepconv3_bn False\n",
            "add_5 False\n",
            "block8_sepconv1_act False\n",
            "block8_sepconv1 False\n",
            "block8_sepconv1_bn False\n",
            "block8_sepconv2_act False\n",
            "block8_sepconv2 False\n",
            "block8_sepconv2_bn False\n",
            "block8_sepconv3_act False\n",
            "block8_sepconv3 False\n",
            "block8_sepconv3_bn False\n",
            "add_6 False\n",
            "block9_sepconv1_act False\n",
            "block9_sepconv1 False\n",
            "block9_sepconv1_bn False\n",
            "block9_sepconv2_act False\n",
            "block9_sepconv2 False\n",
            "block9_sepconv2_bn False\n",
            "block9_sepconv3_act False\n",
            "block9_sepconv3 False\n",
            "block9_sepconv3_bn False\n",
            "add_7 False\n",
            "block10_sepconv1_act False\n",
            "block10_sepconv1 False\n",
            "block10_sepconv1_bn False\n",
            "block10_sepconv2_act False\n",
            "block10_sepconv2 False\n",
            "block10_sepconv2_bn False\n",
            "block10_sepconv3_act False\n",
            "block10_sepconv3 False\n",
            "block10_sepconv3_bn False\n",
            "add_8 False\n",
            "block11_sepconv1_act False\n",
            "block11_sepconv1 False\n",
            "block11_sepconv1_bn False\n",
            "block11_sepconv2_act False\n",
            "block11_sepconv2 False\n",
            "block11_sepconv2_bn False\n",
            "block11_sepconv3_act False\n",
            "block11_sepconv3 False\n",
            "block11_sepconv3_bn False\n",
            "add_9 False\n",
            "block12_sepconv1_act False\n",
            "block12_sepconv1 False\n",
            "block12_sepconv1_bn False\n",
            "block12_sepconv2_act False\n",
            "block12_sepconv2 False\n",
            "block12_sepconv2_bn False\n",
            "block12_sepconv3_act False\n",
            "block12_sepconv3 False\n",
            "block12_sepconv3_bn False\n",
            "add_10 False\n",
            "block13_sepconv1_act False\n",
            "block13_sepconv1 False\n",
            "block13_sepconv1_bn False\n",
            "block13_sepconv2_act False\n",
            "block13_sepconv2 False\n",
            "block13_sepconv2_bn False\n",
            "conv2d_3 False\n",
            "block13_pool False\n",
            "batch_normalization_3 False\n",
            "add_11 False\n",
            "block14_sepconv1 True\n",
            "block14_sepconv1_bn True\n",
            "block14_sepconv1_act True\n",
            "block14_sepconv2 True\n",
            "block14_sepconv2_bn True\n",
            "block14_sepconv2_act True\n",
            "global_average_pooling2d True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ft_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.AdamW(), metrics='accuracy')"
      ],
      "metadata": {
        "id": "z6BTmLxHuqdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = ft_model.fit(\n",
        "    x = tfk.applications.xception.preprocess_input(X_train), # We need to apply the preprocessing thought for the MobileNetV2 network\n",
        "    y = y_train,\n",
        "    batch_size = 16,\n",
        "    epochs = 400,\n",
        "    validation_data = (tfk.applications.xception.preprocess_input(X_val), y_val), # We need to apply the preprocessing thought for the MobileNetV2 network\n",
        "    callbacks = [\n",
        "        tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=30, restore_best_weights=True),\n",
        "        tfk.callbacks.ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.9, patience = 8, min_lr = 2e-6)\n",
        "    ]\n",
        ").history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4ZMNtgEuqgh",
        "outputId": "74a6f2fd-63a5-4e7b-81b7-483e71015d7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "846/846 [==============================] - 45s 31ms/step - loss: 0.5213 - accuracy: 0.7436 - val_loss: 0.4153 - val_accuracy: 0.8140 - lr: 0.0010\n",
            "Epoch 2/400\n",
            "846/846 [==============================] - 25s 29ms/step - loss: 0.4561 - accuracy: 0.7836 - val_loss: 0.3882 - val_accuracy: 0.8400 - lr: 0.0010\n",
            "Epoch 3/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.4201 - accuracy: 0.8104 - val_loss: 0.4096 - val_accuracy: 0.8180 - lr: 0.0010\n",
            "Epoch 4/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.3859 - accuracy: 0.8320 - val_loss: 0.5028 - val_accuracy: 0.7940 - lr: 0.0010\n",
            "Epoch 5/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.3603 - accuracy: 0.8455 - val_loss: 0.3977 - val_accuracy: 0.8220 - lr: 0.0010\n",
            "Epoch 6/400\n",
            "846/846 [==============================] - 23s 27ms/step - loss: 0.3163 - accuracy: 0.8639 - val_loss: 0.4056 - val_accuracy: 0.8260 - lr: 0.0010\n",
            "Epoch 7/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.2835 - accuracy: 0.8818 - val_loss: 0.4082 - val_accuracy: 0.8360 - lr: 0.0010\n",
            "Epoch 8/400\n",
            "846/846 [==============================] - 23s 27ms/step - loss: 0.2527 - accuracy: 0.8971 - val_loss: 0.4093 - val_accuracy: 0.8260 - lr: 0.0010\n",
            "Epoch 9/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.2154 - accuracy: 0.9118 - val_loss: 0.5153 - val_accuracy: 0.8040 - lr: 0.0010\n",
            "Epoch 10/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.1918 - accuracy: 0.9273 - val_loss: 0.6333 - val_accuracy: 0.8180 - lr: 0.0010\n",
            "Epoch 11/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.1684 - accuracy: 0.9365 - val_loss: 0.5678 - val_accuracy: 0.8100 - lr: 9.0000e-04\n",
            "Epoch 12/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.1406 - accuracy: 0.9469 - val_loss: 0.5723 - val_accuracy: 0.8020 - lr: 9.0000e-04\n",
            "Epoch 13/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.1236 - accuracy: 0.9549 - val_loss: 0.6737 - val_accuracy: 0.7800 - lr: 9.0000e-04\n",
            "Epoch 14/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.1237 - accuracy: 0.9535 - val_loss: 0.7283 - val_accuracy: 0.8120 - lr: 9.0000e-04\n",
            "Epoch 15/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0881 - accuracy: 0.9685 - val_loss: 1.0058 - val_accuracy: 0.7420 - lr: 9.0000e-04\n",
            "Epoch 16/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0950 - accuracy: 0.9648 - val_loss: 0.8069 - val_accuracy: 0.7880 - lr: 9.0000e-04\n",
            "Epoch 17/400\n",
            "846/846 [==============================] - 23s 27ms/step - loss: 0.0924 - accuracy: 0.9673 - val_loss: 0.7709 - val_accuracy: 0.8080 - lr: 9.0000e-04\n",
            "Epoch 18/400\n",
            "846/846 [==============================] - 23s 27ms/step - loss: 0.0812 - accuracy: 0.9724 - val_loss: 0.6474 - val_accuracy: 0.8420 - lr: 9.0000e-04\n",
            "Epoch 19/400\n",
            "846/846 [==============================] - 30s 35ms/step - loss: 0.0722 - accuracy: 0.9737 - val_loss: 0.6066 - val_accuracy: 0.8440 - lr: 9.0000e-04\n",
            "Epoch 20/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0785 - accuracy: 0.9719 - val_loss: 0.8102 - val_accuracy: 0.8040 - lr: 9.0000e-04\n",
            "Epoch 21/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0602 - accuracy: 0.9784 - val_loss: 0.7928 - val_accuracy: 0.8260 - lr: 9.0000e-04\n",
            "Epoch 22/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0680 - accuracy: 0.9751 - val_loss: 0.8125 - val_accuracy: 0.8140 - lr: 9.0000e-04\n",
            "Epoch 23/400\n",
            "846/846 [==============================] - 22s 27ms/step - loss: 0.0569 - accuracy: 0.9795 - val_loss: 1.1780 - val_accuracy: 0.8260 - lr: 9.0000e-04\n",
            "Epoch 24/400\n",
            "846/846 [==============================] - 23s 27ms/step - loss: 0.0597 - accuracy: 0.9787 - val_loss: 0.8796 - val_accuracy: 0.7980 - lr: 9.0000e-04\n",
            "Epoch 25/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0494 - accuracy: 0.9831 - val_loss: 0.8006 - val_accuracy: 0.8340 - lr: 9.0000e-04\n",
            "Epoch 26/400\n",
            "846/846 [==============================] - 23s 27ms/step - loss: 0.0593 - accuracy: 0.9803 - val_loss: 0.7986 - val_accuracy: 0.8280 - lr: 9.0000e-04\n",
            "Epoch 27/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0476 - accuracy: 0.9831 - val_loss: 0.9002 - val_accuracy: 0.7960 - lr: 9.0000e-04\n",
            "Epoch 28/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0404 - accuracy: 0.9865 - val_loss: 0.8075 - val_accuracy: 0.8140 - lr: 8.1000e-04\n",
            "Epoch 29/400\n",
            "846/846 [==============================] - 23s 27ms/step - loss: 0.0423 - accuracy: 0.9858 - val_loss: 0.7809 - val_accuracy: 0.8280 - lr: 8.1000e-04\n",
            "Epoch 30/400\n",
            "846/846 [==============================] - 22s 25ms/step - loss: 0.0447 - accuracy: 0.9851 - val_loss: 0.8976 - val_accuracy: 0.8100 - lr: 8.1000e-04\n",
            "Epoch 31/400\n",
            "846/846 [==============================] - 21s 25ms/step - loss: 0.0421 - accuracy: 0.9860 - val_loss: 0.9445 - val_accuracy: 0.7780 - lr: 8.1000e-04\n",
            "Epoch 32/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0296 - accuracy: 0.9901 - val_loss: 0.9282 - val_accuracy: 0.8160 - lr: 8.1000e-04\n",
            "Epoch 33/400\n",
            "846/846 [==============================] - 22s 25ms/step - loss: 0.0375 - accuracy: 0.9866 - val_loss: 0.8417 - val_accuracy: 0.8160 - lr: 8.1000e-04\n",
            "Epoch 34/400\n",
            "846/846 [==============================] - 23s 27ms/step - loss: 0.0314 - accuracy: 0.9895 - val_loss: 0.8948 - val_accuracy: 0.8380 - lr: 8.1000e-04\n",
            "Epoch 35/400\n",
            "846/846 [==============================] - 21s 25ms/step - loss: 0.0320 - accuracy: 0.9897 - val_loss: 0.8789 - val_accuracy: 0.8240 - lr: 8.1000e-04\n",
            "Epoch 36/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0308 - accuracy: 0.9887 - val_loss: 1.0825 - val_accuracy: 0.8400 - lr: 7.2900e-04\n",
            "Epoch 37/400\n",
            "846/846 [==============================] - 22s 25ms/step - loss: 0.0263 - accuracy: 0.9916 - val_loss: 0.7706 - val_accuracy: 0.8420 - lr: 7.2900e-04\n",
            "Epoch 38/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0299 - accuracy: 0.9899 - val_loss: 0.8789 - val_accuracy: 0.8160 - lr: 7.2900e-04\n",
            "Epoch 39/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0256 - accuracy: 0.9910 - val_loss: 1.2364 - val_accuracy: 0.8400 - lr: 7.2900e-04\n",
            "Epoch 40/400\n",
            "846/846 [==============================] - 22s 25ms/step - loss: 0.0302 - accuracy: 0.9891 - val_loss: 1.0301 - val_accuracy: 0.8460 - lr: 7.2900e-04\n",
            "Epoch 41/400\n",
            "846/846 [==============================] - 22s 25ms/step - loss: 0.0184 - accuracy: 0.9934 - val_loss: 1.0228 - val_accuracy: 0.8380 - lr: 7.2900e-04\n",
            "Epoch 42/400\n",
            "846/846 [==============================] - 23s 27ms/step - loss: 0.0291 - accuracy: 0.9902 - val_loss: 0.8801 - val_accuracy: 0.8300 - lr: 7.2900e-04\n",
            "Epoch 43/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0257 - accuracy: 0.9912 - val_loss: 1.2367 - val_accuracy: 0.8040 - lr: 7.2900e-04\n",
            "Epoch 44/400\n",
            "846/846 [==============================] - 21s 25ms/step - loss: 0.0261 - accuracy: 0.9913 - val_loss: 0.8868 - val_accuracy: 0.8120 - lr: 7.2900e-04\n",
            "Epoch 45/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0240 - accuracy: 0.9922 - val_loss: 0.9768 - val_accuracy: 0.8220 - lr: 7.2900e-04\n",
            "Epoch 46/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0283 - accuracy: 0.9898 - val_loss: 0.9756 - val_accuracy: 0.8200 - lr: 7.2900e-04\n",
            "Epoch 47/400\n",
            "846/846 [==============================] - 21s 25ms/step - loss: 0.0258 - accuracy: 0.9921 - val_loss: 1.2105 - val_accuracy: 0.7980 - lr: 7.2900e-04\n",
            "Epoch 48/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0200 - accuracy: 0.9934 - val_loss: 0.9695 - val_accuracy: 0.8360 - lr: 7.2900e-04\n",
            "Epoch 49/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0210 - accuracy: 0.9919 - val_loss: 0.8784 - val_accuracy: 0.8380 - lr: 6.5610e-04\n",
            "Epoch 50/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0176 - accuracy: 0.9936 - val_loss: 0.9530 - val_accuracy: 0.8280 - lr: 6.5610e-04\n",
            "Epoch 51/400\n",
            "846/846 [==============================] - 23s 27ms/step - loss: 0.0217 - accuracy: 0.9919 - val_loss: 1.0317 - val_accuracy: 0.8220 - lr: 6.5610e-04\n",
            "Epoch 52/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 1.0797 - val_accuracy: 0.8380 - lr: 6.5610e-04\n",
            "Epoch 53/400\n",
            "846/846 [==============================] - 22s 25ms/step - loss: 0.0211 - accuracy: 0.9923 - val_loss: 1.0299 - val_accuracy: 0.8420 - lr: 6.5610e-04\n",
            "Epoch 54/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0175 - accuracy: 0.9948 - val_loss: 1.0731 - val_accuracy: 0.8200 - lr: 6.5610e-04\n",
            "Epoch 55/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 0.9892 - val_accuracy: 0.8280 - lr: 6.5610e-04\n",
            "Epoch 56/400\n",
            "846/846 [==============================] - 21s 25ms/step - loss: 0.0200 - accuracy: 0.9942 - val_loss: 1.0124 - val_accuracy: 0.8160 - lr: 6.5610e-04\n",
            "Epoch 57/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0114 - accuracy: 0.9957 - val_loss: 1.0639 - val_accuracy: 0.8100 - lr: 5.9049e-04\n",
            "Epoch 58/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.8827 - val_accuracy: 0.8480 - lr: 5.9049e-04\n",
            "Epoch 59/400\n",
            "846/846 [==============================] - 23s 27ms/step - loss: 0.0114 - accuracy: 0.9964 - val_loss: 1.0136 - val_accuracy: 0.8280 - lr: 5.9049e-04\n",
            "Epoch 60/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0156 - accuracy: 0.9954 - val_loss: 1.5485 - val_accuracy: 0.8100 - lr: 5.9049e-04\n",
            "Epoch 61/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0166 - accuracy: 0.9949 - val_loss: 1.0108 - val_accuracy: 0.8160 - lr: 5.9049e-04\n",
            "Epoch 62/400\n",
            "846/846 [==============================] - 21s 25ms/step - loss: 0.0190 - accuracy: 0.9933 - val_loss: 1.0343 - val_accuracy: 0.8160 - lr: 5.9049e-04\n",
            "Epoch 63/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 1.0257 - val_accuracy: 0.8160 - lr: 5.9049e-04\n",
            "Epoch 64/400\n",
            "846/846 [==============================] - 22s 27ms/step - loss: 0.0138 - accuracy: 0.9960 - val_loss: 1.1631 - val_accuracy: 0.8460 - lr: 5.9049e-04\n",
            "Epoch 65/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0106 - accuracy: 0.9964 - val_loss: 1.1579 - val_accuracy: 0.8040 - lr: 5.9049e-04\n",
            "Epoch 66/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0164 - accuracy: 0.9946 - val_loss: 1.0627 - val_accuracy: 0.8240 - lr: 5.9049e-04\n",
            "Epoch 67/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 1.0550 - val_accuracy: 0.8380 - lr: 5.3144e-04\n",
            "Epoch 68/400\n",
            "846/846 [==============================] - 22s 27ms/step - loss: 0.0168 - accuracy: 0.9948 - val_loss: 1.0120 - val_accuracy: 0.8320 - lr: 5.3144e-04\n",
            "Epoch 69/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 0.9957 - val_accuracy: 0.8380 - lr: 5.3144e-04\n",
            "Epoch 70/400\n",
            "846/846 [==============================] - 23s 27ms/step - loss: 0.0064 - accuracy: 0.9977 - val_loss: 1.0549 - val_accuracy: 0.8100 - lr: 5.3144e-04\n",
            "Epoch 71/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 1.2659 - val_accuracy: 0.8300 - lr: 5.3144e-04\n",
            "Epoch 72/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 1.2261 - val_accuracy: 0.8480 - lr: 5.3144e-04\n",
            "Epoch 73/400\n",
            "846/846 [==============================] - 23s 27ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 1.0930 - val_accuracy: 0.8160 - lr: 5.3144e-04\n",
            "Epoch 74/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0138 - accuracy: 0.9953 - val_loss: 1.1130 - val_accuracy: 0.8400 - lr: 5.3144e-04\n",
            "Epoch 75/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0071 - accuracy: 0.9975 - val_loss: 1.2115 - val_accuracy: 0.8320 - lr: 4.7830e-04\n",
            "Epoch 76/400\n",
            "846/846 [==============================] - 23s 27ms/step - loss: 0.0203 - accuracy: 0.9950 - val_loss: 1.0694 - val_accuracy: 0.8240 - lr: 4.7830e-04\n",
            "Epoch 77/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0131 - accuracy: 0.9959 - val_loss: 1.1105 - val_accuracy: 0.8360 - lr: 4.7830e-04\n",
            "Epoch 78/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 1.1216 - val_accuracy: 0.8260 - lr: 4.7830e-04\n",
            "Epoch 79/400\n",
            "846/846 [==============================] - 22s 27ms/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 1.0864 - val_accuracy: 0.8400 - lr: 4.7830e-04\n",
            "Epoch 80/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 1.2448 - val_accuracy: 0.8300 - lr: 4.7830e-04\n",
            "Epoch 81/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 1.2638 - val_accuracy: 0.8100 - lr: 4.7830e-04\n",
            "Epoch 82/400\n",
            "846/846 [==============================] - 23s 27ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 1.2451 - val_accuracy: 0.8180 - lr: 4.7830e-04\n",
            "Epoch 83/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 1.0712 - val_accuracy: 0.8220 - lr: 4.3047e-04\n",
            "Epoch 84/400\n",
            "846/846 [==============================] - 23s 27ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 1.1346 - val_accuracy: 0.8140 - lr: 4.3047e-04\n",
            "Epoch 85/400\n",
            "846/846 [==============================] - 23s 27ms/step - loss: 0.0129 - accuracy: 0.9965 - val_loss: 1.2956 - val_accuracy: 0.8220 - lr: 4.3047e-04\n",
            "Epoch 86/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 1.1075 - val_accuracy: 0.8240 - lr: 4.3047e-04\n",
            "Epoch 87/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 1.1890 - val_accuracy: 0.8360 - lr: 4.3047e-04\n",
            "Epoch 88/400\n",
            "846/846 [==============================] - 22s 26ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 1.0535 - val_accuracy: 0.8380 - lr: 4.3047e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_accuracy = ft_model.evaluate(tfk.applications.xception.preprocess_input(X_test),y_test,verbose=0)[-1]\n",
        "print('Test set accuracy %.4f' % test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erGzo711x0zD",
        "outputId": "6bbb36ec-4b7d-4e6c-af87-ac8a6297e2e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set accuracy 0.8120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ft_model.save('Xception_NO_INVERSION_finetuned')\n",
        "del ft_model"
      ],
      "metadata": {
        "id": "uWbGf8SS7Mhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "izIK2ILF7V00"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}