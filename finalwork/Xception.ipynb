{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPsiBkFx144kNL/jTd555bq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"4WHPhlAnlljh"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive/My Drive/Deep Learning Challenge"]},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split, KFold\n","from data_preparation import load_data, delete_outliers\n","import numpy as np\n","from visualization import plot_history\n","import tensorflow as tf\n","from tensorflow import keras as tfk\n","from tensorflow.keras import layers as tfkl\n","from tensorflow.keras.metrics import Precision, Recall\n","import matplotlib.pyplot as plt\n","import random\n","import cv2\n","import os"],"metadata":{"id":"xCvC6R5RlrD9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["seed = 24\n","\n","random.seed(seed)\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","np.random.seed(seed)\n","tf.random.set_seed(seed)\n","tf.compat.v1.set_random_seed(seed)"],"metadata":{"id":"U27hz-RalrGS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_data(folder=\"public_data.npz\", resolution=96, head_only=False):\n","    images = []\n","\n","    loaded = np.load(folder, allow_pickle=True)\n","\n","    # Iterate through files in the specified folder\n","    for i, img in enumerate(loaded['data']):\n","        # Normalize image pixel values to a float range [0, 1]\n","        img = (img / 255).astype(np.float32)\n","\n","        # Make the image dataset squared\n","        dim = min(img.shape[:-1])\n","        img = img[(img.shape[0]-dim)//2:(img.shape[0]+dim)//2, (img.shape[1]-dim)//2:(img.shape[1]+dim)//2, :]\n","\n","        #Image resizing\n","        img = tfkl.Resizing(resolution, resolution)(img)\n","\n","        if img is not None:\n","            images.append(img)\n","\n","        if (head_only and i == 9):\n","           break\n","\n","    labels = loaded['labels']\n","    loaded.close()\n","\n","    if (head_only):\n","       labels = labels[:10]\n","\n","    y = LabelEncoder().fit_transform(labels)\n","\n","    return np.array(images), y\n","\n","def display_random_images(X, y, num_img=10):\n","  # Create subplots for displaying items\n","  fig, axes = plt.subplots(2, num_img//2, figsize=(20, 9))\n","  for i in range(num_img):\n","      image = random.randint(0, X.shape[0] - 1)\n","\n","      ax = axes[i%2, i%num_img//2]\n","      ax.imshow(np.clip(X[image], 0, 255))  # Display clipped item images\n","      ax.text(0.5, -0.1, str(image) + ' ' + str(y[image]), size=12, ha=\"center\", transform=ax.transAxes)\n","      ax.axis('off')\n","  plt.tight_layout()\n","  plt.show()\n","\n","#Outliers are deleted simply by comparison with known outlier samples\n","def delete_outliers(X, y):\n","  shrek = 137\n","  trololo = 5143\n","\n","  new_X = []\n","  new_y = []\n","\n","  num_outliers = 0\n","\n","  for i, sample in enumerate(X):\n","    if (not (np.array_equal(sample, X[shrek]) or np.array_equal(sample, X[trololo]))):\n","      new_X.append(sample)\n","      new_y.append(y[i])\n","    else:\n","      num_outliers += 1\n","\n","  return np.array(new_X), np.array(new_y), num_outliers\n","\n","#Accuracy, recall and precision are plotted\n","def plot_history(history, name, patience=20):\n","    plt.figure(figsize=(11,5))\n","    plt.plot(history['accuracy'], alpha=.3, color='#ff7f0e', linestyle='--')\n","    plt.plot(history['val_accuracy'], label='Val Accuracy', alpha=.8, color='#ff7f0e')\n","    plt.plot(history['val_precision'], label='Val Precision', alpha=.8, color='red')\n","    plt.plot(history['val_recall'], label='Val Recall', alpha=.8, color='blue')\n","    plt.legend(loc='upper left')\n","    plt.title(name + ' Accuracy')\n","    plt.grid(alpha=.3)\n","\n","    plt.text(0.5, -0.1, 'Train accuracy: ' + str(round(history['accuracy'][-patience-1], 4)) + ', Val accuracy: ' + str(round(np.max(history['val_accuracy']), 4)), horizontalalignment='center', verticalalignment='center', transform=plt.gca().transAxes)\n","\n","    plt.figure(figsize=(11,5))\n","    plt.plot(history['loss'], alpha=.3, color='#ff7f0e', linestyle='--')\n","    plt.plot(history['val_loss'], label='Val', alpha=.8, color='#ff7f0e')\n","    plt.legend(loc='upper left')\n","    plt.title('Categorical Crossentropy')\n","    plt.grid(alpha=.3)\n","\n","    plt.show()"],"metadata":{"id":"ajzPa3OIlrIe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X, y = load_data('public_data.npz')\n","X, y, num_outliers = delete_outliers(X, y)"],"metadata":{"id":"5l74ZbmulrLF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split data into training and validation sets\n","X_train_0, X_val, y_train_0, y_val = train_test_split(X, y, test_size=500, stratify=y, random_state=seed)\n","\n","print(X_train_0.shape, y_train_0.shape)\n","print(X_val.shape, y_val.shape)"],"metadata":{"id":"dQZ2uDNJlrNW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700162720706,"user_tz":-60,"elapsed":5,"user":{"displayName":"Lorenzo Iori","userId":"16218346580860771751"}},"outputId":"09dddc75-b962-41dc-824c-dfe790f34dae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(4504, 96, 96, 3) (4504, 2)\n","(500, 96, 96, 3) (500, 2)\n"]}]},{"cell_type":"code","source":["#Two different augmentations are implemented, augmenting the whole dataset 2 times and augmenting the minority class once\n","def augment_dataset(X, y):\n","  augment1 = tf.keras.Sequential([\n","      tfkl.RandomFlip(),\n","      tfkl.RandomTranslation(height_factor = (-0.2,0.2), width_factor = (-0.2,0.2), fill_mode = 'reflect'),\n","      tfkl.RandomZoom(0.3, fill_mode = 'reflect'),\n","      tfkl.RandomBrightness(0.1, value_range=(0,1)),\n","  ])\n","\n","  augment2 = tf.keras.Sequential([\n","      tfkl.RandomFlip(),\n","      tfkl.RandomZoom(0.4, fill_mode = 'reflect'),\n","      tfkl.RandomBrightness(0.1, value_range=(0,1)),\n","      tfkl.RandomRotation((-1,1), fill_mode = 'reflect'),\n","  ])\n","\n","  new_X_train_1 = augment2(X[y == 1])\n","  augmented_X_train_2 = augment2(X)\n","  augmented_X_train_1 = augment1(augmented_X_train_2)\n","\n","  X = np.append(X, augmented_X_train_2, axis = 0)\n","  X = np.append(X, augmented_X_train_1, axis = 0)\n","  X = np.append(X, new_X_train_1, axis = 0)\n","\n","  y_tmp = np.append(y, y)\n","  y = np.append(y_tmp, y)\n","  for k in range(new_X_train_1.shape[0]):\n","      y = np.append(y, 1)\n","  return X, y"],"metadata":{"id":"Mj4QnhPqlrPj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, y_train = augment_dataset(X_train_0, y_train_0)\n","\n","#Dataset is shuffle after augmentation\n","indices = np.arange(X_train.shape[0])\n","np.random.shuffle(indices)\n","X_train = X_train[indices]\n","y_train = y_train[indices]\n","\n","# Define key model parameters\n","input_shape = X_train.shape[1:]\n","batch_size = 16\n","epochs = 400\n","\n","print(X_train.shape)\n","print(y_train.shape)\n","print(np.unique(y_train, return_counts=True))"],"metadata":{"id":"qLWKZnxhlrR4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["display_random_images(X_train, y_train)"],"metadata":{"id":"iigHYabLOG71"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Specifies a single block in the architecture\n","def get_block(x, neurons, batch_normalization=False, dropout=0):\n","    x = tfkl.Dense(neurons)(x)\n","    if (batch_normalization):\n","      x = tfkl.BatchNormalization()(x)\n","    x = tfkl.Activation('relu')(x)\n","    x = tfkl.Dropout(dropout)(x)\n","    return x\n","\n","#Function to easily select models, in the parameters you can specify neurons and layers, dropout levels, and dropout after the pretrained model.\n","def build_model(input_shape, learning_rate=1e-4, neurons=[], base_dropout=0, dropouts=[], batch_normalization=False, name=\"model\", weight_decay=3e-5):\n","  xc = tfk.applications.Xception(\n","    input_shape=(96, 96, 3),\n","    include_top=False,\n","    weights=\"imagenet\",\n","    pooling='avg',\n","  )\n","  xc.trainable = False\n","  inputs = tfk.Input(shape=input_shape)\n","  # Connect Xception to the input\n","  x = mobile(inputs)\n","  x = tfkl.Dropout(base_dropout)(x)\n","\n","  for i, n in enumerate(neurons):\n","      x = get_block(x, n, batch_normalization=batch_normalization, dropout=dropouts[i])\n","\n","  # Add a Dense layer with 1 unit and sigmoid activation as the classifier\n","  outputs = tfkl.Dense(1, activation='sigmoid')(x)\n","\n","  # Create a Model connecting input and output\n","  model = tfk.Model(inputs=inputs, outputs=outputs, name=name)\n","\n","  # Compile the model with Binary Cross-Entropy loss and AdamW optimizer\n","  model.compile(loss=tfk.losses.BinaryCrossentropy(), optimizer=tfk.optimizers.AdamW(learning_rate=learning_rate, weight_decay=weight_decay), metrics=['accuracy', tfk.metrics.Precision(name=\"precision\"), tfk.metrics.Recall(name=\"recall\")])\n","\n","  # Display model summary\n","  model.summary()\n","\n","  return model"],"metadata":{"id":"tAbMg5a7lrUY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700160216998,"user_tz":-60,"elapsed":5943,"user":{"displayName":"Lorenzo Iori","userId":"16218346580860771751"}},"outputId":"ac74c28e-588a-4274-a621-538bff355262"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n","83683744/83683744 [==============================] - 4s 0us/step\n"]}]},{"cell_type":"code","source":["models = [\n","    build_model(input_shape, learning_rate=1e-4, neurons=[64, 16], dropouts=[1/7, 1/7], base_dropout=1/5, batch_normalization=True, weight_decay=3e-5),\n","]\n","\n","histories = []\n","\n","patience = 30\n","\n","for i, model in enumerate(models):\n","  histories.append(model.fit(\n","      x = tfk.applications.xception.preprocess_input(X_train * 255), # We need to apply the preprocessing thought for the Xception network\n","      y = y_train,\n","      batch_size = 16,\n","      epochs = 400,\n","      validation_data = (tfk.applications.xception.preprocess_input(X_val * 255), y_val), # We need to apply the preprocessing thought for the Xception network\n","      callbacks = [\n","          tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=patience, restore_best_weights=True),\n","          tfk.callbacks.ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.5, patience = 15, min_lr = 5e-6)\n","      ]\n","  ).history)"],"metadata":{"id":"-oliHEELlrX0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n","\n","for history in histories:\n","  #Training and validation accuracy, precision and recall are plotted, together with area under the curve\n","  predictions = models[i].predict(tfk.applications.xception.preprocess_input(X_val * 255))\n","  predictions = (predictions > 0.5).astype(\"int32\")\n","  fpr, tpr, thresholds = roc_curve(y_val, predictions)\n","  roc_auc = auc(fpr, tpr)\n","  print('AUC: ' + str(roc_auc))\n","  print('Best Epoch: ' + str(len(history['val_accuracy']) - patience))\n","  plot_history(history, patience=30, name=\"\")"],"metadata":{"id":"g8PvVuy7mH3U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = models[0]\n","model.save(\"XceptionModel\")\n","del model"],"metadata":{"id":"S7E-lu3LmH5n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ft_model = tfk.models.load_model('XceptionModel')    # disconnect runtime and reload for finetuning"],"metadata":{"id":"TsmY6cBdzTno"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ft_model.get_layer('xception').trainable = True\n","ft_model.get_layer('xception').summary()"],"metadata":{"id":"h2A_uYFguqVQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Freeze up to last N layers\n","N = 7    # last block\n","for i, layer in enumerate(ft_model.get_layer('xception').layers[:-N]):\n","  layer.trainable=False"],"metadata":{"id":"CliFxQGduqYA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i, layer in enumerate(ft_model.get_layer('xception').layers):\n","  print(layer.name, layer.trainable)"],"metadata":{"id":"_yPceu-Cuqac"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ft_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.AdamW(learning_rate=1e-5, weight_decay=3e-6), metrics='accuracy')"],"metadata":{"id":"z6BTmLxHuqdA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = ft_model.fit(\n","    x = tfk.applications.xception.preprocess_input(X_train), # We need to apply the preprocessing thought for the Xception network\n","    y = y_train,\n","    batch_size = 16,\n","    epochs = 400,\n","    validation_data = (tfk.applications.xception.preprocess_input(X_val), y_val), # We need to apply the preprocessing thought for the Xception network\n","    callbacks = [\n","        tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=20, restore_best_weights=True),\n","        tfk.callbacks.ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.9, patience = 8, min_lr = 2e-6)\n","    ]\n",").history"],"metadata":{"id":"m4ZMNtgEuqgh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ft_model.save('Xception_final')"],"metadata":{"id":"uWbGf8SS7Mhg"},"execution_count":null,"outputs":[]}]}